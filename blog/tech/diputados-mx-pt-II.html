<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>GMARR | Diputados MX. Part II</title><link rel="icon" href="/favicon.ico"/><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/f69083967af022db.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f69083967af022db.css" data-n-g=""/><link rel="preload" href="/_next/static/css/27d63a300b87bca5.css" as="style"/><link rel="stylesheet" href="/_next/static/css/27d63a300b87bca5.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="/_next/static/chunks/webpack-49b6f2937c9ce9f4.js" defer=""></script><script src="/_next/static/chunks/framework-91d7f78b5b4003c8.js" defer=""></script><script src="/_next/static/chunks/main-208998328ec77b24.js" defer=""></script><script src="/_next/static/chunks/pages/_app-b1ee5ab837b2bece.js" defer=""></script><script src="/_next/static/chunks/5-85f465805c106fa8.js" defer=""></script><script src="/_next/static/chunks/pages/blog/tech/%5Bpostid%5D-5592312e6f3559b1.js" defer=""></script><script src="/_next/static/XP9y3xXm4oT6j5U_5l_Gb/_buildManifest.js" defer=""></script><script src="/_next/static/XP9y3xXm4oT6j5U_5l_Gb/_ssgManifest.js" defer=""></script><script src="/_next/static/XP9y3xXm4oT6j5U_5l_Gb/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div><nav class="bg-gray-800"><div class="max-w-7xl mx-auto px-2 sm:px-6 lg:px-8"><div class="relative flex items-center justify-between h-16"><div class="absolute inset-y-0 left-0 flex items-center sm:hidden"><button class="inline-flex items-center justify-center p-2 rounded-md text-gray-400 hover:text-white hover:bg-gray-700 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-white" id="headlessui-disclosure-button-undefined" type="button" aria-expanded="false"><span class="sr-only">Open main menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div><div class="flex-1 flex items-center justify-center sm:items-stretch sm:justify-start"><div class="flex-shrink-0 flex items-center"><img class="block lg:hidden h-16 w-auto" src="https://imagesforpersonalsite.s3.us-west-2.amazonaws.com/gerlog.png" alt="Workflow" href="/index"/><img class="hidden lg:block h-16 w-auto hover:cursor-pointer" src="https://imagesforpersonalsite.s3.us-west-2.amazonaws.com/gerlog.png" alt="Workflow" href="/index"/></div><div class="hidden sm:block sm:ml-6"><div class="flex mt-3 ml-10 space-x-4"><a href="/" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Home</a><a href="/projects" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Projects</a><a href="/blog" class="text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Blog</a></div></div></div><div class="absolute inset-y-0 right-0 flex items-center pr-2 sm:static sm:inset-auto sm:ml-6 sm:pr-0"><div class="ml-3 relative"></div></div></div></div></nav><div class="flex-col items-center justify-center min-h-screen mt-9"><div class="flex-col items-center justify-start ml-11 md:ml-36 space-y-2"><h1 class="text-5xl font-bold">Diputados MX. Part II</h1></div><div class="flex-col items-center justify-start ml-11 md:ml-36 mt-2"><p class="text-sm font-extralight"><span class="font-normal">Fecha: </span> <!-- -->2021-10-05</p><p class="text-sm font-extralight"><span class="font-normal">Autor: </span> <!-- -->gmarr</p></div><div class="mx-8 md:mx-36 my-8"><div class="markdown-styles_markdown-body__39szf"><p>The most impÃ²rtant part of this project was getting the data. The Congress Website has all kinds of interesting data but sometimes is kind of confusing. </p><p>I proceeded to scrape the site using the <code>requests-html</code> library. This library has great flexibility and it&#x27;s easy to learn. Here&#x27;s the <a href="https://docs.python-requests.org/projects/requests-html/en/latest/"><strong>documentation</strong></a> is a library that helps with the scrapping process. </p><p>Before starting any kind of python project, we must create a python virtual environment. The virtual environment helps us to isolate our project from the rest of our files and assure reproducibility. </p><pre><code class="language-python">#  Create the Virtual Environment using venv. 
python3 -m venv env

# Activating the virtual environment
source env/bin/activate
</code></pre><p>Once the Virtual Environment is created, we proceed to create our <code>requirements.txt</code> file</p><pre><code class="language-bash">touch requirements.txt
</code></pre><p>This file contains all the libraries required for this project. </p><pre><code>#requirements.txt
ipykernel
pandas
requests-html
</code></pre></div></div></div><div class="bg-gray-900 mt-8"><div class="flex justify-center"><a rel="noreferrer" target="_blank" href="mailto:me@gmarr.com" class="text-gray-100 font-bold pt-5 hover:underline hover:cursor-pointer">me@gmarr.com</a></div><div class="flex justify-center space-x-9 mt-5 pb-5"><div class="text-right"><a target="_blank" rel="noreferrer" href="https://github.com/germarr/" class="text-gray-100 font-bold pt-5 hover:underline hover:cursor-pointer">Github</a></div><div class="text-center"><a target="_blank" rel="noreferrer" href="https://twitter.com/jerrypod/" class="text-gray-100 font-bold pt-5 hover:underline hover:cursor-pointer">Twitter</a></div><div class="text-left"><a target="_blank" rel="noreferrer" href="https://linkedin.com/in/martinezarroyogerardo" class="text-gray-100 font-bold pt-5 hover:underline hover:cursor-pointer">LinkedIn</a></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"results":[{"id":6,"title":"Diputados MX. Part II","description":"Scrapping the ðŸ‡²ðŸ‡½ congress site using Python, FastAPI and PostgreSQL","content":"The most impÃ²rtant part of this project was getting the data. The Congress Website has all kinds of interesting data but sometimes is kind of confusing. \n\nI proceeded to scrape the site using the `requests-html` library. This library has great flexibility and it's easy to learn. Here's the [**documentation**](https://docs.python-requests.org/projects/requests-html/en/latest/) is a library that helps with the scrapping process. \n\nBefore starting any kind of python project, we must create a python virtual environment. The virtual environment helps us to isolate our project from the rest of our files and assure reproducibility. \n\n```python\n#  Create the Virtual Environment using venv. \npython3 -m venv env\n\n# Activating the virtual environment\nsource env/bin/activate\n```\nOnce the Virtual Environment is created, we proceed to create our `requirements.txt` file\n\n```bash\ntouch requirements.txt\n```\nThis file contains all the libraries required for this project. \n\n```\n#requirements.txt\nipykernel\npandas\nrequests-html\n```\n\n\n\n","slug":"diputados-mx-pt-II","published_at":"2021-10-05T01:49:58.229Z","created_at":"2021-09-28T01:14:49.720Z","updated_at":"2021-12-20T17:29:01.881Z","user":{"id":1,"username":"gmarr","email":"me@gmarr.com","provider":"local","confirmed":true,"blocked":false,"role":1,"created_at":"2021-09-27T19:44:38.166Z","updated_at":"2021-09-27T19:46:35.202Z"}}],"source":{"compiledSource":"var c=Object.defineProperty,h=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var i=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var p=(e,t,r)=\u003et in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:r}):e[t]=r,a=(e,t)=\u003e{for(var r in t||(t={}))i.call(t,r)\u0026\u0026p(e,r,t[r]);if(o)for(var r of o(t))s.call(t,r)\u0026\u0026p(e,r,t[r]);return e},l=(e,t)=\u003eh(e,m(t));var u=(e,t)=\u003e{var r={};for(var n in e)i.call(e,n)\u0026\u0026t.indexOf(n)\u003c0\u0026\u0026(r[n]=e[n]);if(e!=null\u0026\u0026o)for(var n of o(e))t.indexOf(n)\u003c0\u0026\u0026s.call(e,n)\u0026\u0026(r[n]=e[n]);return r};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(r){var n=r,{components:e}=n,t=u(n,[\"components\"]);return mdx(MDXLayout,l(a(a({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"The most imp\\xF2rtant part of this project was getting the data. The Congress Website has all kinds of interesting data but sometimes is kind of confusing. \"),mdx(\"p\",null,\"I proceeded to scrape the site using the \",mdx(\"inlineCode\",{parentName:\"p\"},\"requests-html\"),\" library. This library has great flexibility and it's easy to learn. Here's the \",mdx(\"a\",a({parentName:\"p\"},{href:\"https://docs.python-requests.org/projects/requests-html/en/latest/\"}),mdx(\"strong\",{parentName:\"a\"},\"documentation\")),\" is a library that helps with the scrapping process. \"),mdx(\"p\",null,\"Before starting any kind of python project, we must create a python virtual environment. The virtual environment helps us to isolate our project from the rest of our files and assure reproducibility. \"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-python\"}),`#  Create the Virtual Environment using venv. \npython3 -m venv env\n\n# Activating the virtual environment\nsource env/bin/activate\n`)),mdx(\"p\",null,\"Once the Virtual Environment is created, we proceed to create our \",mdx(\"inlineCode\",{parentName:\"p\"},\"requirements.txt\"),\" file\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-bash\"}),`touch requirements.txt\n`)),mdx(\"p\",null,\"This file contains all the libraries required for this project. \"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),`#requirements.txt\nipykernel\npandas\nrequests-html\n`)))}MDXContent.isMDXComponent=!0;\n","scope":{}}},"__N_SSG":true},"page":"/blog/tech/[postid]","query":{"postid":"diputados-mx-pt-II"},"buildId":"XP9y3xXm4oT6j5U_5l_Gb","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>